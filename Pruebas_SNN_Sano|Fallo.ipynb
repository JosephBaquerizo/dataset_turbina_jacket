{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pruebas_SNN_Sano|Fallo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU9RbPZsJlEZ5iTuChIsw6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S89oAEYS6y2_"
      },
      "source": [
        "from google.colab import drive\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from scipy.io import loadmat\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFAk8sa27A6k",
        "outputId": "e7adb088-654b-47da-847d-c17ac6c20cdb"
      },
      "source": [
        "# Establecemos conexión con Google Drive para acceder a la carpeta de datasets\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X99tJsHY7E-G"
      },
      "source": [
        "# Guardamos la dirección de los datasets (experimentos) en una variable para utilizala posteriormente\n",
        "dataset_datos_dir = 'drive/MyDrive/DATOS_EXPERIMENTALES_JACKET/DATOS'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-j9UR907F2W"
      },
      "source": [
        "# Obtenemos una lista con todos los nombres de los archivos relacionados a los experimentos realizados\n",
        "dataset_datos_files = [dataset_datos_dir+'/'+filename for filename in listdir(dataset_datos_dir) if isfile(join(dataset_datos_dir, filename))]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiAG551j7Hgh"
      },
      "source": [
        "# Creamos listas en donde se almacenarán los archivos relacionados a experimentos de fisura y experimentos de perno flojo respectivamente\n",
        "datos_fisura = []\n",
        "datos_pernoflojo = []\n",
        "datos_replica = []\n",
        "datos_normal = []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-c85d9k7JbJ"
      },
      "source": [
        "# Iteramos los nombres de todos los archivos en la lista general previamente creada\n",
        "for filename in listdir(dataset_datos_dir):\n",
        "  # Obtenemos el nombre del archivo tal cual, sin direcciones previas\n",
        "  if isfile(join(dataset_datos_dir, filename)):\n",
        "    nombre_archivo = filename.split('.')[0]\n",
        "    # El estado de fisura se asocia al número 3 en los nombres de los archivos, si cumple la condición el archivo, guardamos en la lista datos_fisura\n",
        "    if (nombre_archivo.split('_')[0] == '3'):\n",
        "      datos_fisura.append(dataset_datos_dir + '/' + filename)\n",
        "    # El estado de fisura se asocia al número 4 en los nombres de los archivos, si cumple la condición el archivo, guardamos en la lista datos_pernoflojo\n",
        "    elif (nombre_archivo.split('_')[0] == '4'):\n",
        "      datos_pernoflojo.append(dataset_datos_dir + '/' + filename)\n",
        "    # El estado de fisura se asocia al número 4 en los nombres de los archivos, si cumple la condición el archivo, guardamos en la lista datos_pernoflojo\n",
        "    elif (nombre_archivo.split('_')[0] == '1'):\n",
        "      datos_normal.append(dataset_datos_dir + '/' + filename)\n",
        "    # El estado de fisura se asocia al número 4 en los nombres de los archivos, si cumple la condición el archivo, guardamos en la lista datos_pernoflojo\n",
        "    elif (nombre_archivo.split('_')[0] == '2'):\n",
        "      datos_replica.append(dataset_datos_dir + '/' + filename)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n3wQXV27Nni"
      },
      "source": [
        "Datos Fisura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW1xgRAg7Pg0"
      },
      "source": [
        "# Se crean 2 listas, una asociada al número de experimento y otra asociada al nivel de white noise presente durante el experimento \n",
        "numero_experimentos_fisura = []\n",
        "amplitud_experimentos_fisura = []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_74jHFA7QNT"
      },
      "source": [
        "# Iteramos los nombres de los archivos dentro del conjunto que contiene los datos de fisura\n",
        "for nombre_archivo in datos_fisura:\n",
        "  # Obtenemos el nombre del experimento\n",
        "  nombre_experimento = nombre_archivo.split('/')[4]\n",
        "  # Obtenemos el número del experimento\n",
        "  numero_experimento = nombre_experimento.split('_')[1]\n",
        "  # Obtenemos el nivel de white noise del experimento\n",
        "  amplitud_experimento = nombre_experimento.split('.')[0].split('_')[2].replace('A', '')\n",
        "  # Agregamos el número del experimento a la lista numero_experimentos_fisura creada anteriormente\n",
        "  numero_experimentos_fisura.append(int(numero_experimento))\n",
        "  # Agregamos el nivel de white noise del experimento a la lista amplitud_experimentos_fisura creada anteriormente\n",
        "  if amplitud_experimento == '05':\n",
        "    amplitud_experimento = 0.5\n",
        "    amplitud_experimentos_fisura.append(amplitud_experimento)\n",
        "  else:\n",
        "    amplitud_experimentos_fisura.append(int(amplitud_experimento))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzCYlZpj7Ryt"
      },
      "source": [
        "# Creamos un DataFrame vacío\n",
        "df_fisura = pd.DataFrame()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0DO-SI77R4m"
      },
      "source": [
        "# Iteramos por rango la lista datos_fisura\n",
        "for indice in range(len(datos_fisura)):\n",
        "  # Obtenemos la dirección dentro de la iteración correspondiente\n",
        "  direccion = datos_fisura[indice]\n",
        "  # Transformamos el .mat a un formato en el que se pueda transformar a DataFrame\n",
        "  mat = loadmat(direccion)\n",
        "  df = pd.DataFrame(mat['data'])\n",
        "  # Para todos los valores del experimento, creamos columnas en donde sus valores se asocian con el nivel de wn y el # de experimento\n",
        "  df['#_exp'] = numero_experimentos_fisura[indice]\n",
        "  df['amplitud'] = amplitud_experimentos_fisura[indice]\n",
        "  # Colocamos al final del DataFrame df_fisura creado el nuevo DataFrame \n",
        "  df_fisura = pd.concat([df_fisura, df], axis = 0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfsTX8M97XWA",
        "outputId": "a64e9414-c708-4590-a214-38940fb918d6"
      },
      "source": [
        "# Si dividimos para 99097 el df_fisura deberíamos obtener 20 experimentos en total\n",
        "len(df_fisura)/99097"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMvvDQ2L7Zj-"
      },
      "source": [
        "# Establecemos 2 listas, una con los posibles experimentos y otra con los posibles niveles de white noise, lo cual nos ayudará a segmentar los datos\n",
        "experimentos = [1, 2, 3, 4, 5]\n",
        "wns = [0.5, 1, 2, 3]\n",
        "# Creamos una lista en donde pondremos todas las imágenes creadas, segmentadas por experimento y white noise\n",
        "arreglo_imagenes_por_experimento_fisura = []\n",
        "\n",
        "# Iteramos por experimento y por nivel de white noise\n",
        "for i in experimentos:\n",
        "  for j in wns:\n",
        "    # Creamos filtros que nos permiten identificar el experimento por su número asociado y por su nivel de white noise dentro del conjunto de datos\n",
        "    filter1 = df_fisura[\"#_exp\"] == i\n",
        "    filter2 = df_fisura[\"amplitud\"] == j\n",
        "    # Filtramos y deshacemos las filas que no corresponden a la búsqueda\n",
        "    dataset_experimento = df_fisura.where(filter1 & filter2).dropna()\n",
        "    # Creamos arreglo en donde almacenaremos listas de imágenes asociadas a cada columna en un experimento individual\n",
        "    arreglo_matrices_asociadas = []\n",
        "\n",
        "    # En el conjunto filtrado, iteramos por cada columna (de la columna 0 a la 23)\n",
        "    for n in range(24):\n",
        "      # Establecemos un límite inferior y un límite superior\n",
        "      indice_inicio = 0\n",
        "      indice_fin = 256\n",
        "      # Del conjunto filtrado, obtenemos un subconjunto con muestras cada 6 pasos\n",
        "      columna_cada_6 = dataset_experimento[n][::6]\n",
        "      # Creamos una lista en donde guardaremos todas las imágenes creadas dentro de la columna en la que se esta iterando\n",
        "      matrices_columna = []\n",
        "    \n",
        "      # Recorremos en valores de 256 la columna del subconjunto creado para generar las imágenes 16x16 correspondientes \n",
        "      while indice_fin < len(columna_cada_6):\n",
        "        # Guardamos el conjunto de 256 datos dentro de un arreglo\n",
        "        vector = columna_cada_6[indice_inicio:indice_fin]\n",
        "        # Redimensionamos el arreglo (de 1x256 a 16x16)\n",
        "        matriz = vector.to_numpy().reshape((16, 16))\n",
        "        # Agregamos la imagen dentro de la lista matrices_columna\n",
        "        matrices_columna.append(matriz)\n",
        "        # Establecemos el nuevo límite inferior y superior en donde se encontrarán los datos de mi nueva imagen 16x16\n",
        "        indice_inicio = indice_fin\n",
        "        indice_fin = indice_fin + 256\n",
        "      \n",
        "      # Agregamos las listas de imágenes 16x16 asociadas a una columna a arreglo_matrices_asociadas\n",
        "      arreglo_matrices_asociadas.append(matrices_columna)\n",
        "    \n",
        "    # Agregamos arreglo_matrices_asociadas a arreglos_imagenes_por_experimento, en donde tenemos listas de listas asociadas a un experimento individual\n",
        "    arreglo_imagenes_por_experimento_fisura.append(arreglo_matrices_asociadas)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGUrrbhb7cha"
      },
      "source": [
        "# Creamos un arreglos general para todas las imágenes de dimensionamiento (24, 16, 16)\n",
        "arreglo_imagenes_fisura = []\n",
        "\n",
        "# Iteramos cada experimento en la lista de experimentos creada previamente\n",
        "for experimento in arreglo_imagenes_por_experimento_fisura:\n",
        "  # Iteramos en un rango de 64 para usarlo posteriormente\n",
        "  for idx in range(64):\n",
        "    # Para cada iteración se crea el arreglo en donde se agregaran las capas correctas de la imagen de dimensionamniento (24, 16, 16)\n",
        "    imagen = []\n",
        "    # Iteramos para cada fila en el experimento (son 24 filas)\n",
        "    for fila in experimento:\n",
        "      # Asociamos por índice los valores de cada lista de imágenes para establecer la relación correcta y agregamos al arreglo creado\n",
        "      capa_imagen = fila[idx]\n",
        "      imagen.append(capa_imagen)\n",
        "\n",
        "    # Transformamos la lista de 24 capas a un arreglo numérico\n",
        "    arreglo_imagenes_fisura.append(np.array(imagen))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmiA8_4I7e72",
        "outputId": "b6b02926-8c1b-4593-dc40-963f05350601"
      },
      "source": [
        "# Revisamos el número de imágenes creadas\n",
        "len(arreglo_imagenes_fisura)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfpWWKGh7gvE"
      },
      "source": [
        "Datos Perno Flojo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wLskYPT7iaE"
      },
      "source": [
        "# Se crean 2 listas, una asociada al número de experimento y otra asociada al nivel de white noise presente durante el experimento \n",
        "numero_experimentos_pernoflojo = []\n",
        "amplitud_experimentos_pernoflojo = []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-knLpfCZ7kaC"
      },
      "source": [
        "# Iteramos los nombres de los archivos dentro del conjunto que contiene los datos de fisura\n",
        "for nombre_archivo in datos_pernoflojo:\n",
        "  # Obtenemos el nombre del experimento\n",
        "  nombre_experimento = nombre_archivo.split('/')[4]\n",
        "  # Obtenemos el número del experimento\n",
        "  numero_experimento = nombre_experimento.split('_')[1]\n",
        "  # Obtenemos el nivel de white noise del experimento\n",
        "  amplitud_experimento = nombre_experimento.split('.')[0].split('_')[2].replace('A', '')\n",
        "  # Agregamos el número del experimento a la lista numero_experimentos_pernoflojo creada anteriormente\n",
        "  numero_experimentos_pernoflojo.append(int(numero_experimento))\n",
        "  # Agregamos el nivel de white noise del experimento a la lista amplitud_experimentos_pernoflojo creada anteriormente\n",
        "  if amplitud_experimento == '05':\n",
        "    amplitud_experimento = 0.5\n",
        "    amplitud_experimentos_pernoflojo.append(amplitud_experimento)\n",
        "  else:\n",
        "    amplitud_experimentos_pernoflojo.append(int(amplitud_experimento))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S26fLJXv7mCo"
      },
      "source": [
        "# Creamos un DataFrame vacío\n",
        "df_pernoflojo = pd.DataFrame()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoIW7ZNE7nqy"
      },
      "source": [
        "# Iteramos por rango la lista datos_fisura\n",
        "for indice in range(len(datos_pernoflojo)):\n",
        "  # Obtenemos la dirección dentro de la iteración correspondiente\n",
        "  direccion = datos_pernoflojo[indice]\n",
        "  # Transformamos el .mat a un formato en el que se pueda transformar a DataFrame\n",
        "  mat = loadmat(direccion)\n",
        "  df = pd.DataFrame(mat['data'])\n",
        "  # Para todos los valores del experimento, creamos columnas en donde sus valores se asocian con el nivel de wn y el # de experimento\n",
        "  df['#_exp'] = numero_experimentos_pernoflojo[indice]\n",
        "  df['amplitud'] = amplitud_experimentos_pernoflojo[indice]\n",
        "  # Colocamos al final del DataFrame df_fisura creado el nuevo DataFrame \n",
        "  df_pernoflojo = pd.concat([df_pernoflojo, df], axis = 0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_1islGY7pFm",
        "outputId": "2527a12f-e8ce-4d1c-a6e4-abcced4bbc48"
      },
      "source": [
        "# Si dividimos para 99097 el df_pernoflojo deberíamos obtener 20 experimentos en total\n",
        "len(df_pernoflojo)/99097"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv9_4ru87qxI"
      },
      "source": [
        "# Establecemos 2 listas, una con los posibles experimentos y otra con los posibles niveles de white noise, lo cual nos ayudará a segmentar los datos\n",
        "experimentos = [1, 2, 3, 4, 5]\n",
        "wns = [0.5, 1, 2, 3]\n",
        "# Creamos una lista en donde pondremos todas las imágenes creadas, segmentadas por experimento y white noise\n",
        "arreglo_imagenes_por_experimento_pernoflojo = []\n",
        "\n",
        "# Iteramos por experimento y por nivel de white noise\n",
        "for i in experimentos:\n",
        "  for j in wns:\n",
        "    # Creamos filtros que nos permiten identificar el experimento por su número asociado y por su nivel de white noise dentro del conjunto de datos\n",
        "    filter1 = df_pernoflojo[\"#_exp\"] == i\n",
        "    filter2 = df_pernoflojo[\"amplitud\"] == j\n",
        "    # Filtramos y deshacemos las filas que no corresponden a la búsqueda\n",
        "    dataset_experimento = df_pernoflojo.where(filter1 & filter2).dropna()\n",
        "    # Creamos arreglo en donde almacenaremos listas de imágenes asociadas a cada columna en un experimento individual\n",
        "    arreglo_matrices_asociadas = []\n",
        "\n",
        "    # En el conjunto filtrado, iteramos por cada columna (de la columna 0 a la 23)\n",
        "    for n in range(24):\n",
        "      # Establecemos un límite inferior y un límite superior\n",
        "      indice_inicio = 0\n",
        "      indice_fin = 256\n",
        "      # Del conjunto filtrado, obtenemos un subconjunto con muestras cada 6 pasos\n",
        "      columna_cada_6 = dataset_experimento[n][::6]\n",
        "      # Creamos una lista en donde guardaremos todas las imágenes creadas dentro de la columna en la que se esta iterando\n",
        "      matrices_columna = []\n",
        "    \n",
        "      # Recorremos en valores de 256 la columna del subconjunto creado para generar las imágenes 16x16 correspondientes \n",
        "      while indice_fin < len(columna_cada_6):\n",
        "        # Guardamos el conjunto de 256 datos dentro de un arreglo\n",
        "        vector = columna_cada_6[indice_inicio:indice_fin]\n",
        "        # Redimensionamos el arreglo (de 1x256 a 16x16)\n",
        "        matriz = vector.to_numpy().reshape((16, 16))\n",
        "        # Agregamos la imagen dentro de la lista matrices_columna\n",
        "        matrices_columna.append(matriz)\n",
        "        # Establecemos el nuevo límite inferior y superior en donde se encontrarán los datos de mi nueva imagen 16x16\n",
        "        indice_inicio = indice_fin\n",
        "        indice_fin = indice_fin + 256\n",
        "      \n",
        "      # Agregamos las listas de imágenes 16x16 asociadas a una columna a arreglo_matrices_asociadas\n",
        "      arreglo_matrices_asociadas.append(matrices_columna)\n",
        "    \n",
        "    # Agregamos arreglo_matrices_asociadas a arreglos_imagenes_por_experimento, en donde tenemos listas de listas asociadas a un experimento individual\n",
        "    arreglo_imagenes_por_experimento_pernoflojo.append(arreglo_matrices_asociadas)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gc_78fP7tO6"
      },
      "source": [
        "# Creamos un arreglos general para todas las imágenes de dimensionamiento (24, 16, 16)\n",
        "arreglo_imagenes_pernoflojo = []\n",
        "\n",
        "# Iteramos cada experimento en la lista de experimentos creada previamente\n",
        "for experimento_i in arreglo_imagenes_por_experimento_pernoflojo:\n",
        "  # Iteramos en un rango de 64 para usarlo posteriormente\n",
        "  for idx in range(64):\n",
        "    # Para cada iteración se crea el arreglo en donde se agregaran las capas correctas de la imagen de dimensionamniento (24, 16, 16)\n",
        "    imagen = []\n",
        "    # Iteramos para cada fila en el experimento (son 24 filas)\n",
        "    for fila in experimento_i:\n",
        "      # Asociamos por índice los valores de cada lista de imágenes para establecer la relación correcta y agregamos al arreglo creado\n",
        "      capa_imagen = fila[idx]\n",
        "      imagen.append(capa_imagen)\n",
        "\n",
        "    # Transformamos la lista de 24 capas a un arreglo numérico\n",
        "    arreglo_imagenes_pernoflojo.append(np.array(imagen))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJtl5rV27vTI",
        "outputId": "4054b4e3-8866-48c9-ae98-7bdacde5f0bc"
      },
      "source": [
        "# Revisamos el número de imágenes creadas\n",
        "len(arreglo_imagenes_pernoflojo)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEyFfCdX7w0c"
      },
      "source": [
        "Datos Réplica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUVJ4Gx67yKa"
      },
      "source": [
        "# Se crean 2 listas, una asociada al número de experimento y otra asociada al nivel de white noise presente durante el experimento \n",
        "numero_experimentos_replica = []\n",
        "amplitud_experimentos_replica = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bNw2hn172VQ"
      },
      "source": [
        "# Iteramos los nombres de los archivos dentro del conjunto que contiene los datos de fisura\n",
        "for nombre_archivo in datos_replica:\n",
        "  # Obtenemos el nombre del experimento\n",
        "  nombre_experimento = nombre_archivo.split('/')[4]\n",
        "  # Obtenemos el número del experimento\n",
        "  numero_experimento = nombre_experimento.split('_')[1]\n",
        "  # Obtenemos el nivel de white noise del experimento\n",
        "  amplitud_experimento = nombre_experimento.split('.')[0].split('_')[2].replace('A', '')\n",
        "  # Agregamos el número del experimento a la lista numero_experimentos_pernoflojo creada anteriormente\n",
        "  numero_experimentos_replica.append(int(numero_experimento))\n",
        "  # Agregamos el nivel de white noise del experimento a la lista amplitud_experimentos_pernoflojo creada anteriormente\n",
        "  if amplitud_experimento == '05':\n",
        "    amplitud_experimento = 0.5\n",
        "    amplitud_experimentos_replica.append(amplitud_experimento)\n",
        "  else:\n",
        "    amplitud_experimentos_replica.append(int(amplitud_experimento))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLhkYLDm74A4"
      },
      "source": [
        "# Creamos un DataFrame vacío\n",
        "df_replica = pd.DataFrame()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwzQ-i6R75u3"
      },
      "source": [
        "# Iteramos por rango la lista datos_fisura\n",
        "for indice in range(len(datos_replica)):\n",
        "  # Obtenemos la dirección dentro de la iteración correspondiente\n",
        "  direccion = datos_replica[indice]\n",
        "  # Transformamos el .mat a un formato en el que se pueda transformar a DataFrame\n",
        "  mat = loadmat(direccion)\n",
        "  df = pd.DataFrame(mat['data'])\n",
        "  # Para todos los valores del experimento, creamos columnas en donde sus valores se asocian con el nivel de wn y el # de experimento\n",
        "  df['#_exp'] = numero_experimentos_replica[indice]\n",
        "  df['amplitud'] = amplitud_experimentos_replica[indice]\n",
        "  # Colocamos al final del DataFrame df_fisura creado el nuevo DataFrame \n",
        "  df_replica = pd.concat([df_replica, df], axis = 0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5yAVmBj77VS",
        "outputId": "ab26557e-b249-498f-d03b-df67078624a5"
      },
      "source": [
        "# Si dividimos para 99097 el df_pernoflojo deberíamos obtener 20 experimentos en total\n",
        "len(df_pernoflojo)/99097"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlY_G49079aB"
      },
      "source": [
        "# Establecemos 2 listas, una con los posibles experimentos y otra con los posibles niveles de white noise, lo cual nos ayudará a segmentar los datos\n",
        "experimentos = [1, 2, 3, 4, 5]\n",
        "wns = [0.5, 1, 2, 3]\n",
        "# Creamos una lista en donde pondremos todas las imágenes creadas, segmentadas por experimento y white noise\n",
        "arreglo_imagenes_por_experimento_replica = []\n",
        "\n",
        "# Iteramos por experimento y por nivel de white noise\n",
        "for i in experimentos:\n",
        "  for j in wns:\n",
        "    # Creamos filtros que nos permiten identificar el experimento por su número asociado y por su nivel de white noise dentro del conjunto de datos\n",
        "    filter1 = df_replica[\"#_exp\"] == i\n",
        "    filter2 = df_replica[\"amplitud\"] == j\n",
        "    # Filtramos y deshacemos las filas que no corresponden a la búsqueda\n",
        "    dataset_experimento = df_replica.where(filter1 & filter2).dropna()\n",
        "    # Creamos arreglo en donde almacenaremos listas de imágenes asociadas a cada columna en un experimento individual\n",
        "    arreglo_matrices_asociadas = []\n",
        "\n",
        "    # En el conjunto filtrado, iteramos por cada columna (de la columna 0 a la 23)\n",
        "    for n in range(24):\n",
        "      # Establecemos un límite inferior y un límite superior\n",
        "      indice_inicio = 0\n",
        "      indice_fin = 256\n",
        "      # Del conjunto filtrado, obtenemos un subconjunto con muestras cada 6 pasos\n",
        "      columna_cada_6 = dataset_experimento[n][::6]\n",
        "      # Creamos una lista en donde guardaremos todas las imágenes creadas dentro de la columna en la que se esta iterando\n",
        "      matrices_columna = []\n",
        "    \n",
        "      # Recorremos en valores de 256 la columna del subconjunto creado para generar las imágenes 16x16 correspondientes \n",
        "      while indice_fin < len(columna_cada_6):\n",
        "        # Guardamos el conjunto de 256 datos dentro de un arreglo\n",
        "        vector = columna_cada_6[indice_inicio:indice_fin]\n",
        "        # Redimensionamos el arreglo (de 1x256 a 16x16)\n",
        "        matriz = vector.to_numpy().reshape((16, 16))\n",
        "        # Agregamos la imagen dentro de la lista matrices_columna\n",
        "        matrices_columna.append(matriz)\n",
        "        # Establecemos el nuevo límite inferior y superior en donde se encontrarán los datos de mi nueva imagen 16x16\n",
        "        indice_inicio = indice_fin\n",
        "        indice_fin = indice_fin + 256\n",
        "      \n",
        "      # Agregamos las listas de imágenes 16x16 asociadas a una columna a arreglo_matrices_asociadas\n",
        "      arreglo_matrices_asociadas.append(matrices_columna)\n",
        "    \n",
        "    # Agregamos arreglo_matrices_asociadas a arreglos_imagenes_por_experimento, en donde tenemos listas de listas asociadas a un experimento individual\n",
        "    arreglo_imagenes_por_experimento_replica.append(arreglo_matrices_asociadas)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MvDm1qP7_md"
      },
      "source": [
        "# Creamos un arreglos general para todas las imágenes de dimensionamiento (24, 16, 16)\n",
        "arreglo_imagenes_replica = []\n",
        "\n",
        "# Iteramos cada experimento en la lista de experimentos creada previamente\n",
        "for experimento_i in arreglo_imagenes_por_experimento_replica:\n",
        "  # Iteramos en un rango de 64 para usarlo posteriormente\n",
        "  for idx in range(64):\n",
        "    # Para cada iteración se crea el arreglo en donde se agregaran las capas correctas de la imagen de dimensionamniento (24, 16, 16)\n",
        "    imagen = []\n",
        "    # Iteramos para cada fila en el experimento (son 24 filas)\n",
        "    for fila in experimento_i:\n",
        "      # Asociamos por índice los valores de cada lista de imágenes para establecer la relación correcta y agregamos al arreglo creado\n",
        "      capa_imagen = fila[idx]\n",
        "      imagen.append(capa_imagen)\n",
        "\n",
        "    # Transformamos la lista de 24 capas a un arreglo numérico\n",
        "    arreglo_imagenes_replica.append(np.array(imagen))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4uNSWTO8BrK",
        "outputId": "40672dd7-3223-4a05-f943-beb307802696"
      },
      "source": [
        "# Revisamos el número de imágenes creadas\n",
        "len(arreglo_imagenes_replica)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyr1LNPQ8DGb"
      },
      "source": [
        "Datos Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT8by5BQ8EMW"
      },
      "source": [
        "# Se crean 2 listas, una asociada al número de experimento y otra asociada al nivel de white noise presente durante el experimento \n",
        "numero_experimentos_normal = []\n",
        "amplitud_experimentos_normal = []"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdLnytlq8Fli"
      },
      "source": [
        "# Iteramos los nombres de los archivos dentro del conjunto que contiene los datos de fisura\n",
        "for nombre_archivo in datos_normal:\n",
        "  # Obtenemos el nombre del experimento\n",
        "  nombre_experimento = nombre_archivo.split('/')[4]\n",
        "  # Obtenemos el número del experimento\n",
        "  numero_experimento = nombre_experimento.split('_')[1]\n",
        "  # Obtenemos el nivel de white noise del experimento\n",
        "  amplitud_experimento = nombre_experimento.split('.')[0].split('_')[2].replace('A', '')\n",
        "  # Agregamos el número del experimento a la lista numero_experimentos_pernoflojo creada anteriormente\n",
        "  numero_experimentos_normal.append(int(numero_experimento))\n",
        "  # Agregamos el nivel de white noise del experimento a la lista amplitud_experimentos_pernoflojo creada anteriormente\n",
        "  if amplitud_experimento == '05':\n",
        "    amplitud_experimento = 0.5\n",
        "    amplitud_experimentos_normal.append(amplitud_experimento)\n",
        "  else:\n",
        "    amplitud_experimentos_normal.append(int(amplitud_experimento))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9H7MPwk8HR_"
      },
      "source": [
        "# Creamos un DataFrame vacío\n",
        "df_normal = pd.DataFrame()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx6s7nmR8Id_"
      },
      "source": [
        "# Iteramos por rango la lista datos_fisura\n",
        "for indice in range(len(datos_normal)):\n",
        "  # Obtenemos la dirección dentro de la iteración correspondiente\n",
        "  direccion = datos_normal[indice]\n",
        "  # Transformamos el .mat a un formato en el que se pueda transformar a DataFrame\n",
        "  mat = loadmat(direccion)\n",
        "  df = pd.DataFrame(mat['data'])\n",
        "  # Para todos los valores del experimento, creamos columnas en donde sus valores se asocian con el nivel de wn y el # de experimento\n",
        "  df['#_exp'] = numero_experimentos_normal[indice]\n",
        "  df['amplitud'] = amplitud_experimentos_normal[indice]\n",
        "  # Colocamos al final del DataFrame df_fisura creado el nuevo DataFrame \n",
        "  df_normal = pd.concat([df_normal, df], axis = 0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tnc9Ocj8J_A",
        "outputId": "e84c6518-f1c0-42f5-f6e6-1288f39b0605"
      },
      "source": [
        "# Si dividimos para 99097 el df_pernoflojo deberíamos obtener 20 experimentos en total NO SABEMOS TODAVIA\n",
        "len(df_normal)/99097"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-YBDuyP8LyV"
      },
      "source": [
        "# Establecemos 2 listas, una con los posibles experimentos y otra con los posibles niveles de white noise, lo cual nos ayudará a segmentar los datos\n",
        "experimentosn = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "wns = [0.5, 1, 2, 3]\n",
        "# Creamos una lista en donde pondremos todas las imágenes creadas, segmentadas por experimento y white noise\n",
        "arreglo_imagenes_por_experimento_normal = []\n",
        "\n",
        "# Iteramos por experimento y por nivel de white noise\n",
        "for i in experimentosn:\n",
        "  for j in wns:\n",
        "    # Creamos filtros que nos permiten identificar el experimento por su número asociado y por su nivel de white noise dentro del conjunto de datos\n",
        "    filter1 = df_normal[\"#_exp\"] == i\n",
        "    filter2 = df_normal[\"amplitud\"] == j\n",
        "    # Filtramos y deshacemos las filas que no corresponden a la búsqueda\n",
        "    dataset_experimento = df_normal.where(filter1 & filter2).dropna()\n",
        "    # Creamos arreglo en donde almacenaremos listas de imágenes asociadas a cada columna en un experimento individual\n",
        "    arreglo_matrices_asociadas = []\n",
        "\n",
        "    # En el conjunto filtrado, iteramos por cada columna (de la columna 0 a la 23)\n",
        "    for n in range(24):\n",
        "      # Establecemos un límite inferior y un límite superior\n",
        "      indice_inicio = 0\n",
        "      indice_fin = 256\n",
        "      # Del conjunto filtrado, obtenemos un subconjunto con muestras cada 6 pasos\n",
        "      columna_cada_6 = dataset_experimento[n][::6]\n",
        "      # Creamos una lista en donde guardaremos todas las imágenes creadas dentro de la columna en la que se esta iterando\n",
        "      matrices_columna = []\n",
        "    \n",
        "      # Recorremos en valores de 256 la columna del subconjunto creado para generar las imágenes 16x16 correspondientes \n",
        "      while indice_fin < len(columna_cada_6):\n",
        "        # Guardamos el conjunto de 256 datos dentro de un arreglo\n",
        "        vector = columna_cada_6[indice_inicio:indice_fin]\n",
        "        # Redimensionamos el arreglo (de 1x256 a 16x16)\n",
        "        matriz = vector.to_numpy().reshape((16, 16))\n",
        "        # Agregamos la imagen dentro de la lista matrices_columna\n",
        "        matrices_columna.append(matriz)\n",
        "        # Establecemos el nuevo límite inferior y superior en donde se encontrarán los datos de mi nueva imagen 16x16\n",
        "        indice_inicio = indice_fin\n",
        "        indice_fin = indice_fin + 256\n",
        "      \n",
        "      # Agregamos las listas de imágenes 16x16 asociadas a una columna a arreglo_matrices_asociadas\n",
        "      arreglo_matrices_asociadas.append(matrices_columna)\n",
        "    \n",
        "    # Agregamos arreglo_matrices_asociadas a arreglos_imagenes_por_experimento, en donde tenemos listas de listas asociadas a un experimento individual\n",
        "    arreglo_imagenes_por_experimento_normal.append(arreglo_matrices_asociadas)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quLOmBAm8OEf"
      },
      "source": [
        "# Creamos un arreglos general para todas las imágenes de dimensionamiento (24, 16, 16)\n",
        "arreglo_imagenes_normal = []\n",
        "\n",
        "# Iteramos cada experimento en la lista de experimentos creada previamente\n",
        "for experimento_i in arreglo_imagenes_por_experimento_normal:\n",
        "  # Iteramos en un rango de 64 para usarlo posteriormente\n",
        "  for idx in range(64):\n",
        "    # Para cada iteración se crea el arreglo en donde se agregaran las capas correctas de la imagen de dimensionamniento (24, 16, 16)\n",
        "    imagen = []\n",
        "    # Iteramos para cada fila en el experimento (son 24 filas)\n",
        "    for fila in experimento_i:\n",
        "      # Asociamos por índice los valores de cada lista de imágenes para establecer la relación correcta y agregamos al arreglo creado\n",
        "      capa_imagen = fila[idx]\n",
        "      imagen.append(capa_imagen)\n",
        "\n",
        "    # Transformamos la lista de 24 capas a un arreglo numérico\n",
        "    arreglo_imagenes_normal.append(np.array(imagen))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxl80M4q8QFP",
        "outputId": "ae333f2b-18bf-42b4-a07e-d7b30047ce20"
      },
      "source": [
        "# Revisamos el número de imágenes creadas\n",
        "len(arreglo_imagenes_normal)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2560"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56xrVNp-8fV1"
      },
      "source": [
        "Pruebas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky60iYcX8gZz"
      },
      "source": [
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Carga un modelo guardado previamente.\n",
        "  \"\"\"\n",
        "  print(f'Cargando modelo guardado de: {model_path}...')\n",
        "  model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N36zvi0Q8hCB",
        "outputId": "8675c0e6-b57d-403b-9fb9-f4da2bd3bdb7"
      },
      "source": [
        "# Almacenamos el modelo en una variable\n",
        "modelo_7_loaded = load_model('drive/MyDrive/modelos/20210712-17041626109450-modelo_SNN_TurbinaJacket_Sano_Fallo.h5')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cargando modelo guardado de: drive/MyDrive/modelos/20210712-17041626109450-modelo_SNN_TurbinaJacket_Sano_Fallo.h5...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5YcS2b88izh"
      },
      "source": [
        "def prueba_prediccion(modelo, arreglo_img1_fisura, arreglo_img2_pernoflojo, arreglo_img3_replica, arreglo_img4_normal):\n",
        "\n",
        "  # Establecemos el modo de manera aleatoria\n",
        "  modo = random.randint(1, 10)\n",
        "\n",
        "  # Inicializamos las imágenes de prueba\n",
        "  imagen_prueba_1 = []\n",
        "  imagen_prueba_2 = []\n",
        "\n",
        "  # Establecemos las condiciones de modo para generar el par de imágenes a comparar\n",
        "  if modo == 1:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img1_fisura)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img1_fisura)\n",
        "  elif modo == 2:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img2_pernoflojo)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img2_pernoflojo)\n",
        "  elif modo == 3:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img1_fisura)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img2_pernoflojo)\n",
        "  elif modo == 4:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img1_fisura)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img3_replica)\n",
        "  elif modo == 5:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img1_fisura)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img4_normal)\n",
        "  elif modo == 6:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img2_pernoflojo)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img3_replica)\n",
        "  elif modo == 7:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img2_pernoflojo)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img4_normal)\n",
        "  elif modo == 8:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img3_replica)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img3_replica)\n",
        "  elif modo == 9:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img3_replica)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img4_normal)\n",
        "  elif modo == 10:\n",
        "    imagen_prueba_1 = random.choice(arreglo_img4_normal)\n",
        "    imagen_prueba_2 = random.choice(arreglo_img4_normal)\n",
        "\n",
        "  # Expandimos dimensiones para poder ingresar las imágenes al modelo (relacionado a número de batches)\n",
        "  imagen_prueba_1 = np.expand_dims(imagen_prueba_1, axis=-1)\n",
        "  imagen_prueba_2 = np.expand_dims(imagen_prueba_2, axis=-1)\n",
        "\n",
        "  imagen_prueba_1 = np.expand_dims(imagen_prueba_1, axis=0)\n",
        "  imagen_prueba_2 = np.expand_dims(imagen_prueba_2, axis=0)\n",
        "\n",
        "  # Realizamos predicción\n",
        "  prediccion_prueba = modelo.predict([imagen_prueba_1, imagen_prueba_2])[0][0]\n",
        "  prediccion_prueba_redondeada = round(modelo.predict([imagen_prueba_1, imagen_prueba_2])[0][0])\n",
        "\n",
        "  # Establecemos condiciones para mostrar distintos mensajes de acuerdo a la combinación escogida aleatoriamente\n",
        "  if modo == 1:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: fisura\")\n",
        "    print(\"Segunda imagen: fisura\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1  else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 2:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: perno flojo\")\n",
        "    print(\"Segunda imagen: perno flojo\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 3:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: fisura\")\n",
        "    print(\"Segunda imagen: perno flojo\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 4:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: fisura\")\n",
        "    print(\"Segunda imagen: réplica\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: no similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 5:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: fisura\")\n",
        "    print(\"Segunda imagen: normal\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: no similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 6:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: perno flojo\")\n",
        "    print(\"Segunda imagen: réplica\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: no similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 7:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: pernoflojo\")\n",
        "    print(\"Segunda imagen: normal\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: no similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 8:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: réplica\")\n",
        "    print(\"Segunda imagen: réplica\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 9:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: réplica\")\n",
        "    print(\"Segunda imagen: normal\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")\n",
        "  if modo == 10:\n",
        "    print(\"---------- Resultados ----------\")\n",
        "    print(\"Primera imagen: normal\")\n",
        "    print(\"Segunda imagen: normal\")\n",
        "    print(\"Predicción: similares\") if prediccion_prueba_redondeada == 1 else print(\"Predicción: no similares\")\n",
        "    print(\"Descripción real: similares\")\n",
        "    print(f\"Porcentaje: '{prediccion_prueba*100:.2f}%\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls899T828mad",
        "outputId": "22071bfa-74b0-45ba-c52d-3f92f47540f0"
      },
      "source": [
        "# Realizamos pruebas\n",
        "prueba_prediccion(modelo_7_loaded, arreglo_imagenes_fisura, arreglo_imagenes_pernoflojo, arreglo_imagenes_replica, arreglo_imagenes_normal)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- Resultados ----------\n",
            "Primera imagen: fisura\n",
            "Segunda imagen: fisura\n",
            "Predicción: similares\n",
            "Descripción real: similares\n",
            "Porcentaje: '78.42%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}